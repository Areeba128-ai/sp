# -*- coding: utf-8 -*-
"""HMM-Loop.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16y4BjLZ2whCJXJXn_zhK1x4dYii-X1y_
"""

!pip install hmmlearn
import os
import librosa
import numpy as np
from hmmlearn import hmm
import kagglehub

path=kagglehub.dataset_download("clinton5575/mini-speech-commands")
data_folder=path

# Advanced Feature Extraction
def extract_features(file_path):
    signal,sr=librosa.load(file_path,sr=16000)
    mfcc=librosa.feature.mfcc(y=signal,sr=sr,n_mfcc=13)
    delta=librosa.feature.delta(mfcc)
    combined=np.vstack([mfcc,delta])
    return combined.T

# Organize Data Dynamically
word_files={}
labels=[d for d in os.listdir(data_folder)
        if os.path.isdir(os.path.join(data_folder,d)) and not d.startswith('.')]

for label in labels:
    label_path=os.path.join(data_folder,label)
    word_files[label]=[os.path.join(label_path,f)
                       for f in os.listdir(label_path) if f.endswith(".wav")]

# Initialize and Train HMMs
hmm_models={}

print("Training HMMs for each word...")
for label in labels:
    model=hmm.GaussianHMM(n_components=3,covariance_type="diag",n_iter=100)

    X=[]
    lengths=[]
    for file in word_files[label][:40]:
        features=extract_features(file)
        X.append(features)
        lengths.append(len(features))

    X=np.vstack(X)
    model.fit(X,lengths)
    hmm_models[label]=model
    print(f" Trained:{label}")

# Testing Logic
def recognize_speech(test_file):
    features=extract_features(test_file)
    scores={word:model.score(features) for word,model in hmm_models.items()}
    return max(scores,key=scores.get),scores

# Loop Testing on First 3 Files of One Group
test_label="no"
test_files=word_files[test_label][:3]

print("\nTesting first three files from group:",test_label)

for file in test_files:
    prediction,scores=recognize_speech(file)
    print("\nFile:",os.path.basename(file))
    print("Predicted:",prediction)

