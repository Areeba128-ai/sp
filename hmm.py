# -*- coding: utf-8 -*-
"""HMM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16y4BjLZ2whCJXJXn_zhK1x4dYii-X1y_
"""

!pip install hmmlearn
import os
import librosa
import numpy as np
from hmmlearn import hmm
import kagglehub

path=kagglehub.dataset_download("clinton5575/mini-speech-commands")
data_folder=path

# Advanced Feature Extraction
def extract_features(file_path):
    signal,sr=librosa.load(file_path,sr=16000) # Standardize sampling rate
    # Extract 13 MFCCs
    mfcc=librosa.feature.mfcc(y=signal,sr=sr,n_mfcc=13)
    # Delta features
    delta=librosa.feature.delta(mfcc)
    combined=np.vstack([mfcc,delta])
    return combined.T # Shape:(frames,26)

# Organize Data Dynamically
word_files={}
labels=[d for d in os.listdir(data_folder)
        if os.path.isdir(os.path.join(data_folder,d)) and not d.startswith('.')]

for label in labels:
    label_path=os.path.join(data_folder,label)
    word_files[label]=[os.path.join(label_path,f) for f in os.listdir(label_path) if f.endswith('.wav')]

# Initialize and Train HMMs
hmm_models={}

print("Training HMMs for each word...")
for label in labels:
    model=hmm.GaussianHMM(n_components=3,covariance_type="diag",n_iter=100)

    X=[]
    lengths=[]
    for file in word_files[label][:40]:
        features=extract_features(file)
        X.append(features)
        lengths.append(len(features))

    X=np.vstack(X)
    model.fit(X,lengths)
    hmm_models[label]=model
    print(f" Trained:{label}")

# Testing Logic
def recognize_speech(test_file):
    features=extract_features(test_file)
    scores={word:model.score(features) for word,model in hmm_models.items()}
    return max(scores,key=scores.get),scores

# Example Test
sample_test=word_files['no'][0]
prediction,all_scores=recognize_speech(sample_test)
print(f"\nFinal Prediction:{prediction}")

