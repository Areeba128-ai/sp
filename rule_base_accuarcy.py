# -*- coding: utf-8 -*-
"""rule-base-accuarcy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GAlVvHhaV9XV5ckVZC-dADvrJWzy3Di3
"""

import librosa
import numpy as np
import os
import kagglehub
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score,confusion_matrix,ConfusionMatrixDisplay

path=kagglehub.dataset_download("clinton5575/mini-speech-commands")
data_folder=path

labels=[d for d in os.listdir(data_folder)
        if os.path.isdir(os.path.join(data_folder,d)) and not d.startswith('.')]

labels=sorted(labels)

word_files={}
for label in labels:
    label_path=os.path.join(data_folder,label)
    word_files[label]=[os.path.join(label_path,f) for f in os.listdir(label_path) if f.endswith(".wav")]

print("Dataset Summary")
print("--------------")
print("Classes:",labels)
print("Total samples:",sum(len(word_files[l]) for l in labels))
for l in labels:
    print(l,len(word_files[l]))

def rule_based_predict(file_path):
    signal,sr=librosa.load(file_path,sr=None)

    energy=np.sum(signal**2)/len(signal)
    zcr=np.mean(librosa.feature.zero_crossing_rate(signal))

    if energy>0.01 and zcr>0.1:
        return "CONSONANT_HEAVY",energy,zcr
    else:
        return "VOWEL_DOMINANT",energy,zcr

vowel_words=["go","no","yes","up","on","off"]
consonant_words=["stop","left","right","down"]

def true_label(word):
    if word in consonant_words:
        return "CONSONANT_HEAVY"
    else:
        return "VOWEL_DOMINANT"

group_folder=os.path.join(data_folder,"go")
audio_files=[f for f in os.listdir(group_folder) if f.endswith(".wav")][:3]

print("\nAnalyzing Files:",audio_files)

for file in audio_files:
    audio_path=os.path.join(group_folder,file)
    signal,sr=librosa.load(audio_path,sr=None)

    mfcc=librosa.feature.mfcc(y=signal,sr=sr,n_mfcc=13)

    plt.figure(figsize=(6,3))
    plt.imshow(mfcc,aspect='auto',origin='lower')
    plt.title(f"MFCC: {file}")
    plt.colorbar()
    plt.show()

    pred_label,energy,zcr=rule_based_predict(audio_path)

    if energy>0.01:
        energy_label="Loud Sound Detected"
    else:
        energy_label="Silent Sound Detected"

    if zcr>0.1:
        zcr_label="Unvoiced Consonant"
    else:
        zcr_label="Voiced Sound"

    print("\nFILE:",file)
    print("Energy:",energy_label,"| value:",energy)
    print("ZCR:",zcr_label,"| value:",zcr)
    print("Rule Based Recognized Pattern:",pred_label)

y_true=[]
y_pred=[]

for word in labels:
    for file_path in word_files[word][:20]:
        try:
            y_true.append(true_label(word))
            pred_label,_,_=rule_based_predict(file_path)
            y_pred.append(pred_label)
        except:
            continue

acc=accuracy_score(y_true,y_pred)
print("\nRule-Based Accuracy:",acc)

cm=confusion_matrix(
    y_true,y_pred,
    labels=["VOWEL_DOMINANT","CONSONANT_HEAVY"]
)

disp=ConfusionMatrixDisplay(
    confusion_matrix=cm,
    display_labels=["Vowel Dominant","Consonant Heavy"]
)

disp.plot()
plt.title("Rule-Based Confusion Matrix")
plt.show()

