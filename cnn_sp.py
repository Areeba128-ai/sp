# -*- coding: utf-8 -*-
"""CNN_SP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16y4BjLZ2whCJXJXn_zhK1x4dYii-X1y_
"""

import os
import shutil
import kagglehub


raw_path = kagglehub.dataset_download("clinton5575/mini-speech-commands")
SOURCE_PATH = raw_path

#  where  want to work
DEST_PATH = "/kaggle/working/mini_speech_commands"
os.makedirs(DEST_PATH, exist_ok=True)

# Loop through every folder in your dataset
print("Organizing dataset...")
for folder_name in os.listdir(SOURCE_PATH):
    source_folder = os.path.join(SOURCE_PATH, folder_name)

    # Check if it's a directory (to skip README or hidden files)
    if os.path.isdir(source_folder) and not folder_name.startswith('.'):
        dest_folder = os.path.join(DEST_PATH, folder_name)

        # Copy the entire folder to  working directory
        if not os.path.exists(dest_folder):
            shutil.copytree(source_folder, dest_folder)
            print(f" Processed: {folder_name}")

print(f"\nDataset is now ready at: {DEST_PATH}")

import librosa
import librosa.display
import matplotlib.pyplot as plt
import kagglehub


audio_path = "/kaggle/working/mini_speech_commands/down/004ae714_nohash_0.wav"

signal, sr = librosa.load(audio_path, sr=None)

plt.figure(figsize=(10,4))
librosa.display.waveshow(signal, sr=sr)
plt.title("Audio Waveform")
plt.xlabel("Time")
plt.ylabel("Amplitude")
plt.show()

print("Sampling Rate:", sr)
print("Duration (sec):", len(signal)/sr)


import os
import librosa
import numpy as np

DATASET_PATH="/kaggle/working/mini_speech_commands/"

# This correctly identifies your folders:off,up,on,etc.
classes=[d for d in os.listdir(DATASET_PATH) if os.path.isdir(os.path.join(DATASET_PATH,d)) and not d.startswith('.')]

X=[]
y=[]

for label,class_name in enumerate(classes):
    class_path=os.path.join(DATASET_PATH,class_name)
    print(f"Processing class:{class_name}")

    for file in os.listdir(class_path):
        if not file.lower().endswith(".wav"):
            continue

        file_path=os.path.join(class_path,file)

        # Add lines to fix the 0 samples issue
        try:
            # Load the audio(sr=None keeps original sampling rate)
            signal,sr=librosa.load(file_path,duration=1.0)

            # Extract MFCC features
            mfcc=librosa.feature.mfcc(y=signal,sr=sr,n_mfcc=40)

            # Append transpose so time is first dimension
            X.append(mfcc.T)
            y.append(label)
        except Exception as e:
            continue

print(f"Total Samples Successfully Loaded:{len(X)}")

import numpy as np
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical

X=pad_sequences(X,padding='post',dtype='float32')

X=X[...,np.newaxis]

y=to_categorical(y)

X_train,X_test,y_train,y_test=train_test_split(
    X,y,test_size=0.2,random_state=42
)

print("Training Shape:",X_train.shape)
print("Testing Shape:",X_test.shape)


test_loss,test_accuracy=model.evaluate(X_test, y_test)
print("Test Accuracy:", test_accuracy)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=X_train.shape[1:]),
    MaxPooling2D((2,2)),
    Dropout(0.3),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D((2,2)),
    Dropout(0.3),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(len(classes), activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

history = model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=20,
    batch_size=32
)

test_loss, test_accuracy = model.evaluate(X_test, y_test)
print("Test Accuracy:", test_accuracy)


MAX_LEN = X_train.shape[1]
print("Fixed MFCC time steps:",MAX_LEN)

from tensorflow.keras.preprocessing.sequence import pad_sequences
import numpy as np
import librosa

def predict_sound(file_path):
    signal,sr=librosa.load(file_path,duration=3)

    mfcc=librosa.feature.mfcc(y=signal,sr=sr,n_mfcc=40)
    mfcc=mfcc.T

    #  Force SAME padding as training
    mfcc=pad_sequences(
        [mfcc],
        maxlen=MAX_LEN,
        padding='post',
        truncating='post',
        dtype='float32'
    )

    mfcc=mfcc[...,np.newaxis]

    prediction=model.predict(mfcc)
    predicted_class=classes[np.argmax(prediction)]
    return predicted_class

print("Predicted Sound:",
      predict_sound("/kaggle/working/mini_speech_commands/down/0132a06d_nohash_1.wav"))

